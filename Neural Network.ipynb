{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7acef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     810.270083\n",
      "b    1024.800000\n",
      "c       8.000000\n",
      "d       7.941556\n",
      "dtype: float64 a   -791.132347\n",
      "b     65.002541\n",
      "c     -7.700000\n",
      "d     -7.913990\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28306"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Data.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "df = train\n",
    "\n",
    "X = df[['a','b']]\n",
    "y = df[['c','d']]\n",
    "\n",
    "X=X.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.001\n",
    "maximum = df.max(axis=0) # will return max value of each column\n",
    "minimum = df.min(axis=0) # will return max value of each column\n",
    "\n",
    "print(maximum,minimum)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af35aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE NORMALIZEATION [ 0.01511941  2.53939614 -0.01100439 ...  0.01184836 -1.17219779\n",
      "  2.54752167]\n",
      "AFTER NORMALIZEATION [0.5000843  0.65928895 0.49843668 ... 0.49987799 0.4252009  0.65980142]\n",
      "AFTER DENORMALIZEATION [ 0.01511941  2.53939614 -0.01100439 ...  0.01184836 -1.17219779\n",
      "  2.54752167]\n"
     ]
    }
   ],
   "source": [
    "def norm(x,maximum,minimum):\n",
    "    y = ((x-minimum)/(maximum-minimum))\n",
    "    return y\n",
    "\n",
    "def denorm(x,maximum,minimum):\n",
    "    y = (x*(maximum-minimum)+minimum)\n",
    "    return y\n",
    "print(\"BEFORE NORMALIZEATION\",y[:,1])\n",
    "X[:,0] = norm(X[:,0],maximum[0],minimum[0])\n",
    "X[:,1] = norm(X[:,1],maximum[1],minimum[1])\n",
    "y[:,0] = norm(y[:,0],maximum[2],minimum[2])\n",
    "y[:,1] = norm(y[:,1],maximum[3],minimum[3])\n",
    "print(\"AFTER NORMALIZEATION\",y[:,1])\n",
    "print(\"AFTER DENORMALIZEATION\",denorm(y[:,1],maximum[3],minimum[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab00be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.input = 2\n",
    "        self.output = 2\n",
    "        self.hidden = 4\n",
    "        \n",
    "        self.W1 = np.random.rand(self.input, self.hidden) \n",
    "        self.W2 = np.random.rand(self.hidden, self.output)\n",
    "\n",
    "    def ForwardProp(self, X):\n",
    "        self.weight = np.dot(X, self.W1)\n",
    "        self.weight2 = self.sigmoidActivation(self.weight) \n",
    "        self.weight3 = np.dot(self.weight2, self.W2) \n",
    "        output = self.sigmoidActivation(self.weight3)\n",
    "        return output\n",
    "        \n",
    "    def sigmoidActivation(self, s, deriv=False):\n",
    "        if (deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1 + np.exp(-s))\n",
    "    \n",
    "    def backwardProp(self, X, y, output):\n",
    "        #backward propogate through the network\n",
    "        self.output_error = y - output # error in output\n",
    "        self.output_delta = self.output_error * self.sigmoidActivation(output, deriv=True)\n",
    "        \n",
    "        self.z2_error = self.output_delta.dot(self.W2.T) #z2 error: how much our hidden layer weights contribute to output error\n",
    "        self.z2_delta = self.z2_error * self.sigmoidActivation(self.weight2, deriv=True) #applying derivative of sigmoid to z2 error\n",
    "        \n",
    "        self.W1 += X.T.dot(self.z2_delta)*lr + momentum * self.W1 # adjusting first set (input -> hidden) weights\n",
    "        self.W2 += self.weight2.T.dot(self.output_delta)*lr + momentum * self.W2 # adjusting second set (hidden -> output) weights\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.ForwardProp(X)\n",
    "        self.backwardProp(X, y, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74897a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE in epochs 1: 0.09858844838901487\n",
      "RMSE 0.3139879749114843\n",
      "W1 [[0.87793519 0.21475107 0.57425822 0.55283247]\n",
      " [0.3513477  0.7557816  0.66223591 0.35442225]]\n",
      "\n",
      "W2 [[0.93304352 0.96740521]\n",
      " [0.55051134 0.4856535 ]\n",
      " [0.82686357 0.46540704]\n",
      " [0.32565609 0.15972775]]\n",
      "\n",
      "\n",
      "MSE in epochs 100: 0.008308098671162232\n",
      "RMSE 0.09114877218680585\n",
      "W1 [[-2.09707439 -4.16296213 -3.78662669 -3.67964481]\n",
      " [-3.06260721 -1.54301987 -2.41300084 -2.70050073]]\n",
      "\n",
      "W2 [[ 1.06228174  0.85832379]\n",
      " [-0.67821637 -0.79369894]\n",
      " [ 0.2094177  -0.56962548]\n",
      " [ 0.42896598 -0.53114255]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "RMSE = []\n",
    "MSE = []\n",
    "\n",
    "i=0\n",
    "while True: #trains the NN 1000 times\n",
    "    i=i+1\n",
    "    RMSE.append(str(np.sqrt(((y - NN.ForwardProp(X))**2).mean())))\n",
    "    MSE.append(str(np.mean(np.square(y - NN.ForwardProp(X)))))\n",
    "\n",
    "    if (i % 100 == 0 or i == 1): \n",
    "        print(\"\")\n",
    "        print(\"MSE in epochs\",str(i)+\": \" + str(np.mean(np.square(y - NN.ForwardProp(X)))))\n",
    "        print(\"RMSE\", np.sqrt(((y - NN.ForwardProp(X))**2).mean()))\n",
    "        print(\"W1\",NN.W1)\n",
    "        print(\"\")\n",
    "        print(\"W2\",NN.W2)\n",
    "        print(\"\")\n",
    "\n",
    "    #len(error) > 1 and round(float(error[-1]),11)== round(float(error[-2]),11) or \n",
    "    if(len(RMSE) > 1 and round(float(RMSE[-1]),6)== round(float(RMSE[-2]),6)):\n",
    "        print(\"Loss: same in previous epoch, stopping the training at epoch number\",i)\n",
    "        print(\"\")\n",
    "        print(\"MSE in epochs\",str(i)+\": \" + str(np.mean(np.square(y - NN.ForwardProp(X)))))\n",
    "        print(\"RMSE\", np.sqrt(((y - NN.ForwardProp(X))**2).mean()))\n",
    "        print(\"W1\",NN.W1)\n",
    "        print(\"\")\n",
    "        print(\"W2\",NN.W2)\n",
    "        print(\"\")\n",
    "        break\n",
    "    else:\n",
    "        NN.train(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "df = pd.DataFrame({'RMSE':RMSE})\n",
    "\n",
    "df = df.astype(float)\n",
    "df.plot(figsize=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9333d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test\n",
    "\n",
    "X = df[['a','b']]\n",
    "y = df[['c','d']]\n",
    "\n",
    "X=X.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "print(\"BEFORE NORMALIZEATION\",y[:,1])\n",
    "y[:,0] = norm(y[:,0],maximum[2],minimum[2])\n",
    "y[:,1] = norm(y[:,1],maximum[3],minimum[3])\n",
    "print(\"AFTER NORMALIZEATION\",y[:,1])\n",
    "print(\"AFTER DENORMALIZEATION\",denorm(y[:,1],maximum[3],minimum[3]))\n",
    "\n",
    "i=75\n",
    "\n",
    "output = NN.ForwardProp(X[i])\n",
    "output[0] = denorm(output[0],maximum[2],minimum[2])\n",
    "output[1] = denorm(output[1],maximum[3],minimum[3])\n",
    "\n",
    "y[i][0] = denorm(y[i][0],maximum[2],minimum[2])\n",
    "y[i][1] = denorm(y[i][1],maximum[3],minimum[3])\n",
    "\n",
    "\n",
    "inputt = X[i]\n",
    "inputt[0] = norm(output[0],maximum[0],minimum[0])\n",
    "inputt[1] = norm(output[1],maximum[1],minimum[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")        \n",
    "print(\"Input: \" + str([X[i]]))\n",
    "print(\"\\n\")     \n",
    "print(\"Actual Output: \" + str(y[i]))\n",
    "print(\"RMSE: \" +str(np.sqrt(((y - NN.ForwardProp(X))**2).mean())))\n",
    "print(\"\\n\")\n",
    "print(\"Predicted Output: \" , output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627b0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
